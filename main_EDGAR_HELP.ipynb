{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 5fd22109-7e01-4065-9ca2-9a71dffe7c8e"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Local_NAV as local\n",
    "import Global_NAV as glob\n",
    "import Motion_CTR_ as mctrl\n",
    "import Kalman_FIL as kfil\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import IPython\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "from matplotlib import colors\n",
    "from cvision import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robot has arrived to the final goal\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eaell\\Documents\\epfl\\ma1\\MICRO-452 Basics of mobile robotics\\project\\main_EDGAR_HELP.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eaell/Documents/epfl/ma1/MICRO-452%20Basics%20of%20mobile%20robotics/project/main_EDGAR_HELP.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m threshold_for_convergence \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eaell/Documents/epfl/ma1/MICRO-452%20Basics%20of%20mobile%20robotics/project/main_EDGAR_HELP.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m path \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/eaell/Documents/epfl/ma1/MICRO-452%20Basics%20of%20mobile%20robotics/project/main_EDGAR_HELP.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eaell/Documents/epfl/ma1/MICRO-452%20Basics%20of%20mobile%20robotics/project/main_EDGAR_HELP.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eaell/Documents/epfl/ma1/MICRO-452%20Basics%20of%20mobile%20robotics/project/main_EDGAR_HELP.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39m# Definition of the references used to map the space\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eaell/Documents/epfl/ma1/MICRO-452%20Basics%20of%20mobile%20robotics/project/main_EDGAR_HELP.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         color_ref1 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mref1.jpg\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Global variables\n",
    "state = 0\n",
    "obst = [0,0,0,0,0]\n",
    "motors_speed = [0,0]\n",
    "not_arrived = True\n",
    "k = 0\n",
    "C_conv_toThymio_right = 67.60908181\n",
    "C_conv_toThymio_left = 67.82946137\n",
    "L = 104\n",
    "R = 20\n",
    "Ts = 0.02 # sampling time\n",
    "# Initial state covariance matrix\n",
    "P_k_minus_1 = np.array([[0.1, 0, 0],\n",
    "                        [0, 0.1, 0],\n",
    "                        [0, 0, 0.1]])\n",
    "P_k = P_k_minus_1\n",
    "threshold_for_convergence = 50\n",
    "\n",
    "path = []\n",
    "while True:\n",
    "    if state == 0:\n",
    "        # Definition of the references used to map the space\n",
    "        color_ref1 = cv2.imread('ref1.jpg')\n",
    "        ref1 = Obj(color_ref1, 50, 2, np.array([[0,0]]))\n",
    "        color_ref2 = cv2.imread('ref2.jpg')\n",
    "        ref2 = Obj(color_ref2, 100, 2, np.array([[0,0]]))\n",
    "        color_ref3 = cv2.imread('ref3.jpg')\n",
    "        ref3 = Obj(color_ref3, 100, 2, np.array([[0,0]]))\n",
    "        map = Map(ref1, ref2, ref3)\n",
    "\n",
    "        # Definition of the objects to recognize in the space\n",
    "        color_obstacle = cv2.imread('obstacle.jpg')\n",
    "        obstacle = Obj(color_obstacle, 700, 4)\n",
    "        color_goal = cv2.imread('goal.jpg')\n",
    "        goal = Obj(color_goal, 100, 4)\n",
    "        color_left_mark = cv2.imread('left_mark.jpg')\n",
    "        left_mark = Obj(color_left_mark, 50, 2)\n",
    "        color_right_mark = cv2.imread('right_mark.jpg')\n",
    "        right_mark = Obj(color_right_mark, 50, 2)\n",
    "        thymio = Robot(right_mark, left_mark)\n",
    "\n",
    "        # Open the video\n",
    "        # For a livestream\n",
    "        #video = cv2.VideoCapture(0)\n",
    "        # or with a prerecorded video\n",
    "        video = cv2.VideoCapture('test3.avi')\n",
    "        if (video.isOpened()== False): \n",
    "            print(\"Error opening video stream or file\")\n",
    "        \n",
    "        # Recognition of the view with the map and path planning\n",
    "        path_found = False\n",
    "        while not (path_found):\n",
    "            ret, frame = video.read()\n",
    "            if ret == True:\n",
    "                matrix = map.matrix(frame, [obstacle], thymio, goal)\n",
    "                if glob.check_matrix(matrix):\n",
    "                    path = glob.global_path(matrix)\n",
    "                    N = len(path)\n",
    "                    path_found = True\n",
    "                    print('Path :', path)\n",
    "                    print('Robot position : ', thymio.localize(frame,map)[0])\n",
    "                    print('Robot direction : ', vector_to_angle(thymio.localize(frame,map)[1]))\n",
    "                    state_estimate_k = np.array([thymio.localize(frame,map)[0,0],thymio.localize(frame,map)[0,1],vector_to_angle(thymio.localize(frame,map)[1])]) \n",
    "        \n",
    "        # Navigation\n",
    "        state = 1    \n",
    "        # Global navigation state\n",
    "        if state == 1:\n",
    "\n",
    "            while not_arrived == True:\n",
    "                #Check if there is obstacles\n",
    "                prox_horizontal = local.read_prox_sensors(node,client)\n",
    "                obst = [prox_horizontal[0], prox_horizontal[1], prox_horizontal[2], prox_horizontal[3], prox_horizontal[4]]\n",
    "                state = local.update_state(state,obst,client)\n",
    "\n",
    "                # Update temporary goal\n",
    "\n",
    "                if k < N-1:\n",
    "                    theta_goal_temp = (math.atan2(path[0,k+1]-path[0,k], path[1,k+1]-path[1,k]) + np.pi) % (np.pi/2) - np.pi\n",
    "                v, w = mctrl.control_law(state_estimate_k, path[0,k], path[1,k], theta_goal_temp)\n",
    "                vr, vl = mctrl.convert_velocity2RL(v,w,C_conv_toThymio_right, C_conv_toThymio_left,L,R)\n",
    "                vr = int(vr)\n",
    "                vl = int(vl)\n",
    "                mctrl.set_motors(vl,vr,node)\n",
    "                \n",
    "                camera_obstructed = 1\n",
    "                # Check if camera is obstructed\n",
    "                if video.isOpened:\n",
    "                    ret, frame = video.read()\n",
    "                    if ret == True:\n",
    "                        if np.size(thymio.localize(frame,map)[1], 0) > 0:\n",
    "                            camera_obstructed = 0\n",
    "                            print('Path :', path)\n",
    "                            print('Robot position : ', thymio.localize(frame,map)[0])\n",
    "                            print('Robot direction : ', vector_to_angle(thymio.localize(frame,map)[1]))\n",
    "                            z_k_observation_vector = np.array([thymio.localize(frame,map)[0][0],thymio.localize(frame,map)[0][1],vector_to_angle(thymio.localize(frame,map)[1])]) \n",
    "                            P_k_minus_1 = P_k\n",
    "                            state_estimate_k,P_k = kfil.ekf(z_k_observation_vector, state_estimate_k, [v,w] , P_k_minus_1, Ts, camera_obstructed)\n",
    "                        else:\n",
    "                            z_k_observation_vector = np.array([state_estimate_k[0], state_estimate_k[1], state_estimate_k[2]])\n",
    "                            state_estimate_k,P_k = kfil.ekf(z_k_observation_vector, state_estimate_k, [v,w] , P_k_minus_1, Ts, camera_obstructed)\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                if np.linalg.norm(state_estimate_k[:2] - np.array([path[0,k], path[1,k]])) < threshold_for_convergence:\n",
    "                    k = k+1\n",
    "                    if k == N-1:\n",
    "                        not_arrived = False\n",
    "                        print('The robot has arrived to the final goal')\n",
    "                    break \n",
    "                time.sleep(Ts)\n",
    "            state = 3                                               \n",
    "\n",
    "\n",
    "        # Local navigation state\n",
    "        if state == 2: \n",
    "            \n",
    "            #We get the sensor value\n",
    "            prox_horizontal = local.read_prox_sensors(node,client)\n",
    "            \n",
    "            #We fill the obst list with the sensor value\n",
    "            obst = [prox_horizontal[0], prox_horizontal[1], prox_horizontal[2], prox_horizontal[3], prox_horizontal[4]]\n",
    "            \n",
    "            #We calculate the motor speed to avoid the object -> potential field method\n",
    "            motors_speed = local.local_navigation(obst)\n",
    "            \n",
    "            #We set the motor speed\n",
    "            mctrl.set_motors(motors_speed[0],motors_speed[1],node)       \n",
    "            \n",
    "            #We update the state\n",
    "            state = local.update_state(state,obst,client)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "motors_speed = local.global_path()\n",
    "local.set_motors(motors_speed[0],motors_speed[1],node) \n",
    "local.stop_motors(node) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctrl.stop_motors(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
