{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node d4e6a400-466a-4476-a871-0ff69583670e"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Local_NAV as local\n",
    "from Global_NAV_TERMINATOR_VERSION import *\n",
    "import MotionCTR2 as mctrl\n",
    "import Kal_FILTER as kfil\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import IPython\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "from matplotlib import colors\n",
    "from cvision_2 import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening video stream or file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elisa\\Desktop\\MobileProject\\main_TERMINATOR.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_TERMINATOR.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m path_found \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_TERMINATOR.ipynb#W2sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m (path_found):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_TERMINATOR.ipynb#W2sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_TERMINATOR.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39mif\u001b[39;00m ret \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_TERMINATOR.ipynb#W2sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Global variables\n",
    "state = 0\n",
    "obst = [0,0,0,0,0]\n",
    "motors_speed = [0,0]\n",
    "not_arrived = True\n",
    "k = 0\n",
    "C_conv_toThymio_right = 67.60908181\n",
    "C_conv_toThymio_left = 67.82946137\n",
    "L = 104\n",
    "R = 20\n",
    "Ts = 0.5 # sampling time\n",
    "# Initial state covariance matrix\n",
    "P_k_minus_1 = np.array([[0.1, 0, 0],\n",
    "                        [0, 0.1, 0],\n",
    "                        [0, 0, 0.1]])\n",
    "P_k = P_k_minus_1\n",
    "threshold_for_convergence = 20\n",
    "speed0 = 60\n",
    "speedGain = 30\n",
    "\n",
    "path = []\n",
    "while True:\n",
    "    if state == 0:\n",
    "        # Create an adjusted dictionary of 5 markers of 4x4 bits.\n",
    "        aruco_dictionary = cv2.aruco.extendDictionary(5, 4)\n",
    "        # Assign a marker to each objects to be recognized on the map\n",
    "        # Generate three reference markers\n",
    "        detector = create_detector(aruco_dictionary)\n",
    "       \n",
    "\n",
    "        for i in range(5):\n",
    "            marker = cv2.aruco.generateImageMarker(aruco_dictionary, i, 500, np.zeros((6, 6, 1), dtype=\"uint8\"), 1)\n",
    "            cv2.imwrite('marker' + str(i) +'.jpg', marker)\n",
    "        # Definition of the references used to map the space\n",
    "        ref1 = Obj(0, np.array([[0,0]]))\n",
    "        ref2 = Obj(1, np.array([[0,0]]))\n",
    "        ref3 = Obj(2, np.array([[0,0]]))\n",
    "\n",
    "       \n",
    "        # Definition of the objects to recognize in the space\n",
    "        goal = Obj(3, np.array([[]]))\n",
    "        thymio = Obj(4, np.array([[]]))\n",
    "\n",
    "        map = Map(ref1,ref2,ref3,920,660)\n",
    "\n",
    "        objects = np.array([ref1,ref2, ref3, goal, thymio])\n",
    "\n",
    "        # Open the video\n",
    "        # For a livestream\n",
    "        video = cv2.VideoCapture(0)\n",
    "        # or with a prerecorded video\n",
    "        #video = cv2.VideoCapture('test3.avi')\n",
    "        if (video.isOpened()== False): \n",
    "            print(\"Error opening video stream or file\")\n",
    "        \n",
    "        # Recognition of the view with the map and path planning\n",
    "        path_found = False\n",
    "        while not (path_found):\n",
    "            ret, frame = video.read()\n",
    "            if ret == True:\n",
    "                clear_output(wait=True)\n",
    "                show_frame(frame)\n",
    "\n",
    "                detect_objects(frame, detector, objects)\n",
    "                if map.references_detected():\n",
    "                    print('Goal position', map.localize(goal))\n",
    "                    matrix = map.matrix(frame, thymio, goal)\n",
    "\n",
    "                    if check_matrix(matrix):\n",
    "                        path, visitedNodes = global_path(matrix)\n",
    "                        print_path(matrix, path, visitedNodes)\n",
    "                        path = np.multiply(path, 10)\n",
    "                        print(\"PATH : \",path)\n",
    "                        key_points = calculate_angles_along_path(path)\n",
    "                        print(\"Key Points : \",key_points)\n",
    "                        N = np.size(path,1)\n",
    "                        path_found = True\n",
    "                        state_estimate_k = np.array([map.localize(thymio)[0][0],map.localize(thymio)[0][1],-vector_to_angle(map.vec_img2map(thymio.get_img_dir()[0]))])\n",
    "\n",
    "        # Navigation\n",
    "        state = 1    \n",
    "        # Global navigation state\n",
    "    if state == 1:\n",
    "    \n",
    "        while not_arrived == True:\n",
    "\n",
    "            #Check if there is obstacles\n",
    "            prox_horizontal = local.read_prox_sensors(node,client)\n",
    "            obst = [prox_horizontal[0], prox_horizontal[1], prox_horizontal[2], prox_horizontal[3], prox_horizontal[4]]\n",
    "            state = local.update_state(state,obst,client)\n",
    "            if state == 2:\n",
    "                break\n",
    "\n",
    "            # Path following: control law\n",
    "            print(\"Position final goal\", [path[0,k],path[1,k]])\n",
    "            vr, vl = mctrl.control_law(state_estimate_k, key_points[0,k], key_points[1,k],speed0,speedGain)\n",
    "            #control_vector_k_minus_1 = mctrl.convert_velocity2vw(vr,vl,C_conv_toThymio_right, C_conv_toThymio_left,L,R) if we use [v,w] as control variables in state space model\n",
    "            control_vector_k_minus_1 = np.array([vr,vl]) #if we use [vr,vl] as control variables in state space model\n",
    "            print(\"Control vector\", control_vector_k_minus_1)\n",
    "            mctrl.set_motors(vl,vr,node)\n",
    "            \n",
    "            \n",
    "            # Take Thymio position if camera is not obstructed and update state estimate with kalman filter\n",
    "            if video.isOpened:\n",
    "                ret, frame = video.read()\n",
    "                new_frame = frame.copy()\n",
    "                if ret == True:\n",
    "                    \n",
    "                    #clear_output(wait=True)\n",
    "                    detect_objects(frame, detector, objects)\n",
    "                    \n",
    "                    ref1.draw(new_frame, [255,0,0])\n",
    "                    ref2.draw(new_frame, [0,255,0])\n",
    "                    ref3.draw(new_frame, [0,0,255])\n",
    "                    goal.draw(new_frame, [255,255,255])\n",
    "                    thymio.draw(new_frame, [255,0,0])\n",
    "                    #show_frame(new_frame)\n",
    "                    \n",
    "                    \n",
    "                    if map.references_detected(): #camera correctly working\n",
    "\n",
    "                        \n",
    "                        if np.size(map.localize(thymio), 0) > 0: #camera working correctly\n",
    "                            camera_obstructed = 0\n",
    "                            #take robot position from camera\n",
    "                            z_k_observation_vector = np.array([map.localize(thymio)[0][0],map.localize(thymio)[0][1],-vector_to_angle(map.vec_img2map(thymio.get_img_dir()[0]))])  \n",
    "                            print(\"Robot position and angle (rad)\", z_k_observation_vector)  \n",
    "                            # update state estimate with kalman filter\n",
    "                            #state_estimate_k = z_k_observation_vector #if you don't use kalman filter\n",
    "                            state_estimate_k,P_k_minus_1 = kfil.ekf(z_k_observation_vector, state_estimate_k, control_vector_k_minus_1, P_k_minus_1, Ts, camera_obstructed)\n",
    "                            print(\"State_estimate_k\", state_estimate_k)\n",
    "                        else: #camera obstructed\n",
    "                            camera_obstructed = 1\n",
    "                            print(\"WARNING:NOCAMERA--WARNING:NOCAMERA--WARNIN:NOCAMERA--WARNING:NOCAMERA\")\n",
    "                            #Measurements are not updated by camera but only by kalman filter\n",
    "                            state_estimate_k,P_k_minus_1 = kfil.ekf(z_k_observation_vector, state_estimate_k, control_vector_k_minus_1, P_k_minus_1, Ts, camera_obstructed) \n",
    "            \n",
    "            # Check if the robot has arrived to the temporary goal\n",
    "            if np.linalg.norm(state_estimate_k[:2] - np.array([key_points[0,k], key_points[1,k]])) < threshold_for_convergence:\n",
    "                if k ==  len(key_points[0]):\n",
    "                    not_arrived = False\n",
    "                    print('The robot has arrived to the final goal')\n",
    "                    mctrl.stop_motors(node)\n",
    "                    #break\n",
    "                else :\n",
    "                    k = k + 1\n",
    "                print(\"position {} of {} in path: \".format(k,N-1))\n",
    "                \n",
    "\n",
    " \n",
    "            time.sleep(Ts)   \n",
    "\n",
    "\n",
    "    # Local navigation state\n",
    "    if state == 2:         \n",
    "        #We get the sensor value\n",
    "        prox_horizontal = local.read_prox_sensors(node,client)\n",
    "        \n",
    "        #We fill the obst list with the sensor value\n",
    "        obst = [prox_horizontal[0], prox_horizontal[1], prox_horizontal[2], prox_horizontal[3], prox_horizontal[4]]\n",
    "        \n",
    "        #We calculate the motor speed to avoid the object -> potential field method\n",
    "        motors_speed = local.local_navigation(obst)\n",
    "        \n",
    "        #We set the motor speed\n",
    "        mctrl.set_motors(motors_speed[0],motors_speed[1],node)       \n",
    "        #We update the state\n",
    "        state = local.update_state(state,obst,client)\n",
    "        if state == 1:\n",
    "            state_estimate_k = np.array([map.localize(thymio)[0][0],map.localize(thymio)[0][1],-vector_to_angle(map.vec_img2map(thymio.get_img_dir()[0]))])\n",
    "            closest_index = find_closest_keypoint_index(state_estimate_k[:2], key_points)\n",
    "            angle = calculate_angle_between_robot_and_closest(state_estimate_k[:2], key_points, closest_index)\n",
    "            \n",
    "            while angle > 90:\n",
    "                if  closest_index != len(key_points[0]) - 1 :\n",
    "                    distances = calculate_distances_to_keypoints(state_estimate_k[:2], key_points)\n",
    "                    next_closest_index = find_next_closest_keypoint(state_estimate_k[:2], key_points, distances, closest_index)\n",
    "                    closest_index = next_closest_index\n",
    "                    angle_to_closest = calculate_angle_between_robot_and_closest(state_estimate_k[:2], key_points, closest_index)\n",
    "                else :\n",
    "                    break\n",
    "\n",
    "        closest_keypoint = [[key_points[0][closest_index]],[key_points[1][closest_index]]]\n",
    "        vr, vl = mctrl.control_law(state_estimate_k, closest_keypoint[0], closest_keypoint[1],speed0,speedGain)\n",
    "        mctrl.set_motors(vl,vr,node)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "             \n",
    "            \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'Local_NAV' has no attribute 'global_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\elisa\\Desktop\\MobileProject\\main_EDGAR_HELP.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_EDGAR_HELP.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m motors_speed \u001b[39m=\u001b[39m local\u001b[39m.\u001b[39mglobal_path()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_EDGAR_HELP.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m local\u001b[39m.\u001b[39mset_motors(motors_speed[\u001b[39m0\u001b[39m],motors_speed[\u001b[39m1\u001b[39m],node) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/elisa/Desktop/MobileProject/main_EDGAR_HELP.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m local\u001b[39m.\u001b[39mstop_motors(node)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'Local_NAV' has no attribute 'global_path'"
     ]
    }
   ],
   "source": [
    "motors_speed = local.global_path()\n",
    "local.set_motors(motors_speed[0],motors_speed[1],node) \n",
    "local.stop_motors(node) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctrl.stop_motors(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Points: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_key_points(path):\n",
    "    key_points = []\n",
    "    if len(path[0]) < 3:\n",
    "        print(\"Length of path array is less than 3\")\n",
    "        return key_points\n",
    "    for i \n",
    "\n",
    "    return key_points\n",
    "\n",
    "# Example path\n",
    "path = [[1, 2, 1, 1, 1], [1, 2, 3, 4, 5]]\n",
    "key_points = find_key_points(path)\n",
    "print(\"Key Points:\", key_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle at point B: 90.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_angle(A, B, C):\n",
    "    vector_AB = np.array(B) - np.array(A)\n",
    "    vector_BC = np.array(C) - np.array(B)\n",
    "\n",
    "    dot_product = np.dot(vector_AB, vector_BC)\n",
    "    magnitude_AB = np.linalg.norm(vector_AB)\n",
    "    magnitude_BC = np.linalg.norm(vector_BC)\n",
    "\n",
    "    cos_angle = dot_product / (magnitude_AB * magnitude_BC)\n",
    "    angle_rad = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    return angle_deg\n",
    "\n",
    "# Example points A, B, C\n",
    "point_A = [1, 1]\n",
    "point_B = [2, 2]\n",
    "point_C = [1, 3]\n",
    "\n",
    "angle_at_B = calculate_angle(point_A, point_B, point_C)\n",
    "print(\"Angle at point B:\", angle_at_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angles at each point: [[2, 1, 1, 0, 0], [2, 3, 5, 6, 10]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_angles_along_path(path):\n",
    "    key_points = [[], []]\n",
    "    angle_TH = 45\n",
    "    x_coords, y_coords = path[0], path[1]\n",
    "    path_length = len(x_coords)\n",
    "\n",
    "    if path_length < 3 or len(y_coords) != path_length:\n",
    "        print(\"Invalid path format.\")\n",
    "        return angles\n",
    "\n",
    "    for i in range(path_length - 2):\n",
    "        point_A = [x_coords[i], y_coords[i]]\n",
    "        point_B = [x_coords[i + 1], y_coords[i + 1]]\n",
    "        point_C = [x_coords[i + 2], y_coords[i + 2]]\n",
    "\n",
    "        angle_at_point = calculate_angle(point_A, point_B, point_C)\n",
    "        if(angle_at_point > angle_TH):\n",
    "            key_points[0].append(point_B[0])\n",
    "            key_points[1].append(point_B[1]) \n",
    "            \n",
    "            \n",
    "    key_points[0].append(x_coords[-1])\n",
    "    key_points[1].append(y_coords[-1])\n",
    "            \n",
    "    return key_points\n",
    "\n",
    "# Example path with X and Y coordinates\n",
    "example_path = [\n",
    "    [1, 2, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "]\n",
    "\n",
    "angles_along_path = calculate_angles_along_path(example_path)\n",
    "print(\"Angles at each point:\", angles_along_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances to key points: [1.4142135623730951, 1.0, 2.23606797749979, 5.385164807134504]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distance_between_points(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "def calculate_distances_to_keypoints(robot_position, key_points):\n",
    "    distances = []\n",
    "\n",
    "    for i in range(len(key_points[0])):\n",
    "        distance = distance_between_points(robot_position, [key_points[0][i], key_points[1][i]])\n",
    "        distances.append(distance)\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Example robot position and key_points array\n",
    "robot_position = [3, 3]\n",
    "key_points = [\n",
    "    [2,2, 2, 5],\n",
    "    [2,3, 5, 8]\n",
    "]\n",
    "\n",
    "\n",
    "distances_to_keypoints = calculate_distances_to_keypoints(robot_position, key_points)\n",
    "print(\"Distances to key points:\", distances_to_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest key point: [[2], [3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distance_between_points(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "def calculate_distances_to_keypoints(robot_position, key_points):\n",
    "    distances = []\n",
    "\n",
    "    for i in range(len(key_points[0])):\n",
    "        distance = distance_between_points(robot_position, [key_points[0][i], key_points[1][i]])\n",
    "        distances.append(distance)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def find_closest_keypoint_index(robot_position, key_points):\n",
    "    distances = calculate_distances_to_keypoints(robot_position, key_points)\n",
    "    closest_index = np.argmin(distances)\n",
    "    return closest_index\n",
    "\n",
    "# Example robot position and key_points array\n",
    "robot_position = [3, 3]\n",
    "key_points = [\n",
    "    [2,2, 2, 5],\n",
    "    [2,3, 5, 8]\n",
    "]\n",
    "\n",
    "\n",
    "closest_index = find_closest_keypoint_index(robot_position, key_points)\n",
    "closest_keypoint = [\n",
    "    [key_points[0][closest_index]],\n",
    "    [key_points[1][closest_index]]\n",
    "]\n",
    "\n",
    "print(\"Closest key point:\", closest_keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clos [[2], [3]]\n",
      "Angle between robot and closest key point: 135.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distance_between_points(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "def calculate_angle(A, B, C):\n",
    "    vector_AB = np.array(B) - np.array(A)\n",
    "    vector_BC = np.array(C) - np.array(B)\n",
    "\n",
    "    dot_product = np.dot(vector_AB, vector_BC)\n",
    "    magnitude_AB = np.linalg.norm(vector_AB)\n",
    "    magnitude_BC = np.linalg.norm(vector_BC)\n",
    "\n",
    "    cos_angle = dot_product / (magnitude_AB * magnitude_BC)\n",
    "    angle_rad = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    return angle_deg\n",
    "\n",
    "def calculate_angle_between_robot_and_closest(robot_position, key_points, closest_index):\n",
    "    closest_keypoint = [key_points[0][closest_index], key_points[1][closest_index]]\n",
    "\n",
    "    angle = calculate_angle(closest_keypoint, robot_position, [0, 0])\n",
    "    return angle\n",
    "\n",
    "# Example robot position and key_points array\n",
    "robot_position = [3,3]\n",
    "key_points = [\n",
    "    [2,2, 2, 5],\n",
    "    [2,3, 5, 8]\n",
    "]\n",
    "\n",
    "closest_index = find_closest_keypoint_index(robot_position, key_points)\n",
    "angle_to_closest = calculate_angle_between_robot_and_closest(robot_position, key_points, closest_index)\n",
    "print(\"clos\",closest_keypoint)\n",
    "print(\"Angle between robot and closest key point:\", angle_to_closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between robot and closest key point: 18.434948822922017\n",
      "Closest key point: [[10], [15]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distance_between_points(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "def calculate_angle(A, B, C):\n",
    "    vector_AB = np.array(B) - np.array(A)\n",
    "    vector_BC = np.array(C) - np.array(B)\n",
    "\n",
    "    dot_product = np.dot(vector_AB, vector_BC)\n",
    "    magnitude_AB = np.linalg.norm(vector_AB)\n",
    "    magnitude_BC = np.linalg.norm(vector_BC)\n",
    "\n",
    "    cos_angle = dot_product / (magnitude_AB * magnitude_BC)\n",
    "    angle_rad = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    return angle_deg\n",
    "\n",
    "def calculate_angle_between_robot_and_closest(robot_position, key_points, closest_index):\n",
    "    closest_keypoint = [key_points[0][closest_index], key_points[1][closest_index]]\n",
    "\n",
    "    angle = calculate_angle(closest_keypoint, robot_position, [0, 0])\n",
    "    return angle\n",
    "\n",
    "def find_next_closest_keypoint(robot_position, key_points, distances, closest_index):\n",
    "    angles = []\n",
    "    for i in range(len(key_points[0])):\n",
    "        if i != closest_index:\n",
    "            angle = calculate_angle_between_robot_and_closest(robot_position, key_points, i)\n",
    "            angles.append(angle)\n",
    "        else:\n",
    "            angles.append(360)  # Ensuring the closest key point isn't considered again\n",
    "\n",
    "    next_closest_index = np.argmin(angles)\n",
    "    return next_closest_index\n",
    "\n",
    "# Example robot position and key_points array\n",
    "robot_position = [5, 10]\n",
    "key_points = [\n",
    "    [2, 4, 6, 8, 10],\n",
    "    [3, 6, 9, 12, 15]\n",
    "]\n",
    "\n",
    "closest_index = find_closest_keypoint_index(robot_position, key_points)\n",
    "angle_to_closest = calculate_angle_between_robot_and_closest(robot_position, key_points, closest_index)\n",
    "\n",
    "if angle_to_closest > 90 and closest_index != len(key_points[0]) - 1:\n",
    "    distances = calculate_distances_to_keypoints(robot_position, key_points)\n",
    "    next_closest_index = find_next_closest_keypoint(robot_position, key_points, distances, closest_index)\n",
    "    closest_index = next_closest_index\n",
    "    angle_to_closest = calculate_angle_between_robot_and_closest(robot_position, key_points, closest_index)\n",
    "\n",
    "closest_keypoint = [\n",
    "    [key_points[0][closest_index]],\n",
    "    [key_points[1][closest_index]]\n",
    "]\n",
    "\n",
    "print(\"Angle between robot and closest key point:\", angle_to_closest)\n",
    "print(\"Closest key point:\", closest_keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkkk [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]\n",
      "Point [[2], [7]] not found in key_points\n"
     ]
    }
   ],
   "source": [
    "def remove_point(key_points, position):\n",
    "    x, y = position  # Assuming position is a tuple (x, y)\n",
    "    \n",
    "    for coordinates in key_points:\n",
    "        if [x, y] in zip(*key_points):\n",
    "            index_to_remove = key_points[0].index(x)\n",
    "            for coordinates in key_points:\n",
    "                del coordinates[index_to_remove]\n",
    "            return True  # Point removed\n",
    "    return False  # Point not found\n",
    "\n",
    "# Example usage:\n",
    "key_points = [\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10]\n",
    "]\n",
    "\n",
    "robot_position = [[2],[7]]# Robot's position\n",
    "print(\"kkkk\",key_points)\n",
    "\n",
    "removed = remove_point(key_points, robot_position)\n",
    "if removed:\n",
    "    print(f\"Point {robot_position} removed from key_points\")\n",
    "else:\n",
    "    print(f\"Point {robot_position} not found in key_points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
